import json
from app.URLê³¼ìš”ì•½ë¬¸ë§Œë“¤ê¸° import get_latest_video_data, summarize_content, get_transcript_text
from app.ì§€ìˆ˜ì •ë³´ê°€ì ¸ì˜¤ê¸° import fetch_stock_info, calculate_dxy_from_currency_data, get_access_token
from app.íœ´ì¥ì¼êµ¬í•˜ê¸° import get_market_holidays
from urllib.parse import urlparse, parse_qs
from pytz import timezone, utc
from app.redis_client import redis_client
from datetime import datetime
from app.test_config import ALL_SYMBOLS, channels
import pytz
import os
from pathlib import Path
from dotenv import load_dotenv

# url, ìš”ì•½ ì €ì¥ ì½”ë“œ
env_path = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=env_path)

KIS_APP_KEY = os.getenv("KIS_APP_KEY")
KIS_APP_SECRET = os.getenv("KIS_APP_SECRET")
CACHE_PATH = Path(__file__).resolve().parent / "token_cache.json"

def convert_to_kst(published_utc_str):
    seoul_tz = timezone("Asia/Seoul")
    published_utc = datetime.strptime(published_utc_str, "%Y-%m-%dT%H:%M:%SZ")
    published_kst = published_utc.replace(tzinfo=utc).astimezone(seoul_tz)
    return published_kst

def fetch_and_store_youtube_data():
    try:

        seoul_tz = timezone("Asia/Seoul")
        today_date = datetime.now(seoul_tz).date().strftime("%Y-%m-%d")
        updated = False

        for channel in channels:
            country = channel["country"]

            # ì €ì¥ë˜ì–´ìˆëŠ” ë°ì´í„°ì˜ ì €ì¥ëœ ë‚ ì§œ í™•ì¸
            existing_raw = redis_client.hget("youtube_data", country)
            if existing_raw:
                existing_data = json.loads(existing_raw)
                # existing_dataì—ì„œ processed_time ê°€ì ¸ì˜¤ê¸°
                processed_time = existing_data.get('processed_time')
                if processed_time:
                    processed_date = convert_to_kst(processed_time).strftime("%Y-%m-%d")
                    if processed_date == today_date:
                        if existing_data.get('summary_content') is None:

                            # ìš”ì•½ ë‹¤ì‹œ ìƒì„±
                            print(f"âœï¸ {country} â€” summary_content ì—†ìŒ, ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                            url = existing_data.get('url')
                            parsed_url = urlparse(url)
                            query_params = parse_qs(parsed_url.query)
                            video_id_list = query_params.get('v')
                            if not video_id_list:
                                print(f"âŒ {country} â€” video_id ì¶”ì¶œ ì‹¤íŒ¨, ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                                continue
                            video_id = video_id_list[0]
                            transcript = get_transcript_text(video_id)
                            if not transcript:
                                print(f"âŒ {country} â€” transcript ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨, ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                                continue
                            # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
                            existing_data['summary_content'] = transcript
                            # Redis ë®ì–´ì“°ê¸°
                            redis_client.hset("youtube_data", country, json.dumps(existing_data))
                            print(f"ğŸ”” {country} â€” ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€ ì €ì¥ ì™„ë£Œ")
                        if existing_data.get('summary_result') is None:
                            transcript = existing_data.get('summary_content')
                            summary_result = summarize_content(transcript)

                            existing_data['summary_result'] = summary_result
                            # ì €ì¥ ì‹œê°„ ì—…ë°ì´íŠ¸ (UTC)
                            existing_data['processed_time'] = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
                            # Redis ë®ì–´ì“°ê¸°
                            redis_client.hset("youtube_data", country, json.dumps(existing_data))
                            if summary_result == None:
                                print(f"ğŸ”” {country} â€” ìš”ì•½ ê²°ê³¼ ì¶”ê°€ë˜ì§€ ì•ŠìŒ")
                            else:
                                print(f"ğŸ”” {country} â€” ìš”ì•½ ê²°ê³¼ ì¶”ê°€ ì €ì¥ ì™„ë£Œ")
                            updated = True
                        continue
                        # processed_timeì´ ì˜¤ëŠ˜ ë‚ ì§œê°€ ì•„ë‹ˆë©´ ìƒˆë¡œ ì¡°íšŒ
                    else:
                        print(f"âš ï¸ {country} â€” processed_timeì´ ì˜¤ëŠ˜ì´ ì•„ë‹ˆì–´ì„œ ìƒˆë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")
                else:
                    print(f"âš ï¸ {country} â€” processed_time ì—†ìŒ, ìƒˆë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")
            else:
                print(f"ğŸ’¡ {country} â€” ê¸°ì¡´ ë°ì´í„° ì—†ìŒ, ìƒˆë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.")

                # existing_dataì—ì„œ processed_time ê°€ì ¸ì˜¤ê¸°
            # ğŸ” ìƒˆ ì˜ìƒ ì„œì¹˜
            video_data = get_latest_video_data(channel)
            if not video_data:
                print(f"âŒ {country} â€” ì˜ìƒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ìŠ¤í‚µí•©ë‹ˆë‹¤.")
                continue

            video_date_str = convert_to_kst(video_data['publishedAt']).strftime("%Y-%m-%d")

            # âœ… ì˜¤ëŠ˜ ì˜ìƒì¸ì§€ í™•ì¸
            if video_date_str != today_date:
                print(f"â­ï¸ {country} â€” ì˜¤ëŠ˜ ì˜ìƒ ì•„ë‹˜ ({video_date_str})")
                continue

            # âœ… ìš”ì•½ ìƒì„±
            summary_result = summarize_content(video_data['summary_content'])
            video_data['summary_result'] = summary_result

            # âœ… ì €ì¥ ì‹œê°„ ì¶”ê°€ (UTC ê¸°ì¤€)
            video_data['processed_time'] = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")

            # âœ… Redisì— í•´ë‹¹ êµ­ê°€ë§Œ ì €ì¥ (ë®ì–´ì“°ê¸°)
            redis_client.hset("youtube_data", country, json.dumps(video_data))
            print(f"ğŸ”” {country} ë°ì´í„° ì €ì¥ë¨: {video_data['url']}")
            updated = True

        return "âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ" if updated else "âœ… ëª¨ë“  ë°ì´í„°ëŠ” ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤."

    except Exception as e:
        return f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def fetch_and_store_chart_data():
    results = []
    token = get_access_token(KIS_APP_KEY, KIS_APP_SECRET)
    # ALL_SYMBOLSì— ì •ì˜ëœ ê°ê°ì˜ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì²˜ë¦¬
    for source, symbol_dict in ALL_SYMBOLS.items():
        for category, symbols in symbol_dict.items():
            source_data = {}
            if category =='currency':
                new_data = calculate_dxy_from_currency_data(token)
                source_data['dxy'] = new_data
                results.append(
                    f"âœ… [{source.upper()} - {category.upper()} - {'dxy'.upper()}] {len(new_data['data'])}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            for name, symbol in symbols.items():
                try:
                    # fetch_stock_info í˜¸ì¶œ ì‹œ, symbolê³¼ source ì „ë‹¬
                    new_data = fetch_stock_info(symbol, token, category,source=source, day_num=200)
                    source_data[name] = new_data

                    results.append(f"âœ… [{source.upper()} - {category.upper()} - {name.upper()}] {len(new_data['data'])}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                except Exception as e:
                    results.append(f"âŒ [{source.upper()} - {category.upper()} - {name.upper()}] ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

            try:
                # Redisì— ì €ì¥í•  ë°ì´í„° í˜•ì‹
                redis_key = "chart_data"
                 # ê¸°ì¡´ ë°ì´í„°ë¥¼ Redisì—ì„œ ì¡°íšŒí•˜ì—¬ ë¹„êµ
                existing_data_raw = redis_client.hget(redis_key, category)
                existing_data = json.loads(existing_data_raw.decode()) if existing_data_raw else {}

                updated_data = existing_data.copy()
                updated_data.update(source_data)  # ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ëœ nameë§Œ ë®ì–´ì”€

                existing_data_str = json.dumps(existing_data, sort_keys=True)
                new_data_str = json.dumps(updated_data, sort_keys=True)
                if existing_data_str == new_data_str:
                    results.append(f"â­ï¸ {category.upper()} ë°ì´í„° ë³€ê²½ ì—†ìŒ, ì €ì¥ ìƒëµ")
                else:
                    processed_time = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
                    redis_client.hset(redis_key, category + "_processed_time", processed_time)
                    redis_client.hset(redis_key, category, new_data_str)
                    results.append(f"âœ… ì „ì²´ {category.upper()} ë°ì´í„° Redisì— ì €ì¥ ì™„ë£Œ")

            except Exception as e:
                results.append(f"âŒ ì „ì²´ {category.upper()} ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    return "\n".join(results)

def fetch_and_store_holiday_data():
    results = []
    try:

        holiday_data = get_market_holidays()
        redis_key = "market_holidays"
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        new_data_str = json.dumps(holiday_data, ensure_ascii=False, sort_keys=True)
        redis_client.hset(redis_key, "all_holidays", new_data_str)
        redis_client.hset(redis_key, "all_holidays_timestamp", timestamp)
        results.append(f"âœ… ì „ì²´ ê³µíœ´ì¼ ë°ì´í„° Redisì— ì €ì¥ ì™„ë£Œ (ì €ì¥ ì‹œê°„: {timestamp})")

    except Exception as e:
        results.append(f"âŒ ì „ì²´ ê³µíœ´ì¼ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def save_daily_data():
    youtube_data = redis_client.hgetall("youtube_data")

    kst = pytz.timezone('Asia/Seoul')
    now_kst = datetime.now(kst)

    today_kst = datetime.now(kst).date()  # í•œêµ­ ê¸°ì¤€ ì˜¤ëŠ˜
    date_str = now_kst.strftime("%Y%m%d")  # Redis í•„ë“œ í‚¤ìš© (ì˜ˆ: 20250615)
    save_dict = {}

    filtered_data = {}
    for country_bytes, json_bytes in youtube_data.items():
        try:
            country = country_bytes.decode()
            json_str = json_bytes.decode()
            data = json.loads(json_str)

            # processed_time ê°€ì ¸ì˜¤ê¸° (UTCë¡œ ë˜ì–´ìˆë‹¤ê³  ê°€ì •)
            processed_time_utc = datetime.strptime(data['processed_time'], "%Y-%m-%dT%H:%M:%SZ")
            processed_time_utc = pytz.utc.localize(processed_time_utc)

            # UTC â†’ í•œêµ­ ì‹œê°„
            processed_time_kst = processed_time_utc.astimezone(kst)

            # ì˜¤ëŠ˜ ì €ì¥ëœ ê²ƒë§Œ í•„í„°ë§
            if processed_time_kst.date() == today_kst:
                filtered_data[country] = data

        except (KeyError, ValueError, json.JSONDecodeError):
            print(f"âš ï¸ {country} ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
    save_dict = {"youtube_data": filtered_data}
    redis_client.hset("daily_saved_data", date_str, json.dumps(save_dict, ensure_ascii=False))
    print(f"âœ… {len(filtered_data)}ê°œ ì €ì¥ ì™„ë£Œ â†’ Redis key: daily_saved_data, field: {date_str}")

def scheduled_store():
    now = datetime.now(timezone('Asia/Seoul'))
    print("ğŸ“ˆ chart data ì €ì¥ ì‹œì‘...")
    stored_result = fetch_and_store_chart_data()
    print(stored_result)

    if 11 <= now.hour < 15:  # 11ì‹œ ~ 14ì‹œ 59ë¶„
        print("â° Scheduled store running at", now.strftime("%Y-%m-%d %H:%M"))
        youtube_result = fetch_and_store_youtube_data()
        print(youtube_result)



    # âœ… ì›”ìš”ì¼ì¼ ë•Œë§Œ ì‹¤í–‰
    if now.weekday() == 0:  # 0 = ì›”ìš”ì¼
        print("ğŸ“… ì›”ìš”ì¼: íœ´ì¼ ë°ì´í„° ì €ì¥ ì²´í¬ ì¤‘...")

        try:
            timestamp_str = redis_client.hget("market_holidays", "all_holidays_timestamp")
            if timestamp_str:
                timestamp = datetime.strptime(timestamp_str.decode(), "%Y-%m-%dT%H:%M:%SZ")
                timestamp_kst = timestamp.replace(tzinfo=timezone('UTC')).astimezone(timezone('Asia/Seoul'))

                if timestamp_kst.date() == now.date():
                    print("â­ï¸ ì˜¤ëŠ˜ ì´ë¯¸ íœ´ì¼ ë°ì´í„°ê°€ ì €ì¥ë¨. ìƒëµí•©ë‹ˆë‹¤.")
                    return

            # ì €ì¥ ì•ˆ ë˜ì–´ ìˆê±°ë‚˜ ë‚ ì§œê°€ ì˜¤ëŠ˜ì´ ì•„ë‹ˆë©´ ì‹¤í–‰
            holiday_result = fetch_and_store_holiday_data()
            print(holiday_result)

        except Exception as e:
            print(f"âŒ Redisì—ì„œ  timestamp í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # âœ… ë°¤ 11ì‹œì—ë§Œ save_daily_data ì‹¤í–‰
    if now.hour == 23:
        print("ğŸ•š 23ì‹œ â†’ í•˜ë£¨ ë°ì´í„° ì €ì¥ ì‹œì‘")
        save_daily_data()


if __name__ == "__main__":

    result = fetch_and_store_youtube_data()
    print(result)
    save_daily_data()

    result = fetch_and_store_chart_data()
    print(result)

    # result = fetch_and_store_holiday_data()
    # print(result)

    # scheduled_store()