import time
from difflib import SequenceMatcher
from youtube_transcript_api import YouTubeTranscriptApi
from pathlib import Path
from dotenv import load_dotenv
env_path = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=env_path)

import requests
import os
import difflib
# ğŸ”‘ YouTube Data API í‚¤ (ë³´ì•ˆì„ ìœ„í•´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ì¶”ì²œ)
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")  # .envì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°

import isodate
from openai import OpenAI
def summarize_content(content):
    if len(content) > 30000:
        return "âŒ ìš”ì•½ ì‹¤íŒ¨: ê¸€ì ìˆ˜(30000) ì´ˆê³¼"
    if not content.strip():
        return "âŒ ìš”ì•½ ì‹¤íŒ¨: ë‚´ìš© ì—†ìŒ"
    client = OpenAI()
    try:

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ì£¼ìš” ë‰´ìŠ¤ë¥¼ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì„¤ëª…í•´ì¤˜. ë¶ˆí•„ìš”í•œ ë„ì… ë¬¸êµ¬ ì—†ì´, ë°”ë¡œ "
                        "ìš”ì  ë‚˜ì—´ í˜•ì‹ìœ¼ë¡œ ì‹œì‘í•´."
                        "ì˜ˆ: 1. **í•µì‹¬ ë‚´ìš© ìš”ì•½**: ì‹¤ì œ ë‚´ìš©..."
                        " ë°˜ë“œì‹œ í•œê¸€ë¡œ ì„¤ëª…í•´ì¤˜"
                    )
                },
                {"role": "user", "content": content}
            ]
        )
        summary = completion.choices[0].message.content
        return summary

    except Exception as e:
        print("âŒ ìš”ì•½ API ì‹¤íŒ¨:", e)
        return "âŒ ìš”ì•½ ì‹¤íŒ¨: GPT í˜¸ì¶œ ì˜¤ë¥˜"


def find_similar_video_id(data, keyword, similarity_threshold=0.7,from_playlist=False):
    keyword = keyword.lower()
    k_len = len(keyword)

    for item in data["items"]:
        if isinstance(item["id"], dict):
            video_id = item["id"].get("videoId")
        else:
            video_id = item["snippet"]["resourceId"]["videoId"]

        videos_check_url = "https://www.googleapis.com/youtube/v3/videos"
        params = {
            "part": "contentDetails",
            "id": video_id,
            "key": YOUTUBE_API_KEY
        }
        response = requests.get(videos_check_url, params=params)
        video_data = response.json()
        duration = isodate.parse_duration(video_data["items"][0]["contentDetails"]['duration'])
        # 10ë¶„ ~ 1ì‹œê°„30ë¶„ ì´í•˜ ì˜ìƒë§Œ
        if duration.total_seconds() >= 5400 or duration.total_seconds() <= 600:
            continue

        title = item["snippet"]["title"]
        text = title.lower()
        max_sim = 0.0

        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
        for i in range(len(text) - k_len + 1):
            window = text[i:i + k_len]
            sim = SequenceMatcher(None, keyword, window).ratio()
            if sim > max_sim:
                max_sim = sim

            if max_sim > similarity_threshold:
                return video_id


def get_latest_video_url(channel):
    channel_handle = channel["channel_handle"]
    keyword = channel["keyword"]
    content_type = channel["content_type"]
    save_fields = channel["save_fields"]


    if content_type=="video":
        channel_url = "https://www.googleapis.com/youtube/v3/channels"
        params = {
            "part": "id",
            "forHandle": channel_handle,
            "key": YOUTUBE_API_KEY
        }

        response = requests.get(channel_url, params=params)
        data = response.json()
        channel_id = data["items"][0]['id']

        search_url = "https://www.googleapis.com/youtube/v3/search"
        params = {
            "part": "snippet",
            "channelId": channel_id,  # ë³€í™˜ëœ ì±„ë„ ID ì‚¬ìš©
            "q": keyword,
            "order": "date",  # ìµœì‹ ìˆœ ì •ë ¬
            "maxResults": 10,
            "key": YOUTUBE_API_KEY,
        }

        response = requests.get(search_url, params=params)
        data = response.json()

        video_id = find_similar_video_id(data, keyword, similarity_threshold=0.7)

    elif content_type=="playlist":
        search_playlist_url = "https://www.googleapis.com/youtube/v3/playlistItems"
        playlist_id = channel_handle
        params = {
            "part": "snippet",
            "playlistId": playlist_id,
            "maxResults": 5,
            "key": YOUTUBE_API_KEY
        }

        response = requests.get(search_playlist_url, params=params)
        data = response.json()

        video_id = find_similar_video_id(data, keyword, similarity_threshold=0.7,from_playlist=True)

    if video_id:
        videos_check_url = "https://www.googleapis.com/youtube/v3/videos"
        params = {
            "part": "snippet",
            "id": video_id,
            "key": YOUTUBE_API_KEY
        }
        response = requests.get(videos_check_url, params=params)
        data = response.json()

        video_title = data["items"][0]["snippet"]["title"]
        video_pbtime = data["items"][0]["snippet"]["publishedAt"]

        if "description" == save_fields:
            summary_content = data["items"][0]["snippet"]["description"]
        elif "subtitle" == save_fields:
            country_to_lang = {
                "Korea": "ko",
                "USA": "en",
                "Japan": "ja",
                "China": "zh",
                # í•„ìš”í•œ ë§Œí¼ ì¶”ê°€ ê°€ëŠ¥
            }
            language_code = country_to_lang.get(channel['country'], "en")  # ê¸°ë³¸ì€ ì˜ì–´
            try:
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                generated_transcript = None
                for transcript in transcript_list:
                    if transcript.is_generated and transcript.language_code == language_code:
                        generated_transcript = transcript
                        break
                if not generated_transcript:
                    for transcript in transcript_list:
                        if transcript.is_generated:
                            generated_transcript = transcript
                            break
                if generated_transcript:
                    transcript = generated_transcript.fetch()
                    full_text = "\n".join([entry.text for entry in transcript])
                    summary_content = full_text
                else:
                    summary_content = ""
            except Exception as e:
                print("âŒ ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:", e)
                summary_content = ""

    summary_result = summarize_content(summary_content)

    return {
            "url": f"https://www.youtube.com/watch?v={video_id}",
            "title": video_title,
            "publishedAt": video_pbtime,
            "summary_target": save_fields,
            "summary_content": summary_content,
            "summary_result": summary_result
        }
    return None  # ì˜ìƒì´ ì—†ì„ ê²½ìš°


# âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":

    channels = [
        {"country": "Korea",
         "channel_handle": "@newskbs",
         "keyword": "[í’€ì˜ìƒ] ë‰´ìŠ¤12",
         "content_type": "video",
         "save_fields": "subtitle"},
        {
            "country": "USA",
            "channel_handle": "PL0tDb4jw6kPymVj5xNNha5PezudD5Qw9L",
            "keyword": "Nightly News Full Episode",
            "content_type": "playlist",
            "save_fields": "subtitle"
        },
        {
            "country": "Japan",
            "channel_handle": "@tbsnewsdig",
            "keyword": "ã€LIVEã€‘æœã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆJapan News Digest Liveï¼‰",
            "content_type": "video",
            "save_fields": "subtitle"
        },
        {
            "country": "China",
            "channel_handle": "PL0eGJygpmOH5xQuy8fpaOvKrenoCsWrKh",
            "keyword": "CCTVã€Œæ–°é—»è”æ’­ã€",
            "content_type": "playlist",
            "save_fields": "description"
        }
    ]

    results = {}
    for channel in channels:
        video_url = get_latest_video_url(channel)
        results[channel["country"]] = video_url

    print(results)  # ìµœì‹  ì˜ìƒ ë§í¬ ì¶œë ¥
